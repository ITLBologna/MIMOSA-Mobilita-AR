# etl
Etl for Mimosa data

Before starting you need to configure the a `.env` file and the add the agencies data in each file.

## Prerequisites:

Ensure that Python is installed on your machine along with the necessary packages and dependencies required for the ETL process.

## 1. Download the data
`python download-dataset.py`

This command downloads all the specified datasets in the input folder set in the .env file.

## 2. Transform the data
`python parse-dataset.py`

This command creates both the combined gtfs folder, which contains a single gtfs feed with all the specified agencies, and single agency folders and zips with a common format. All the transformed data is saved in the output folder set in the .env file.

## 3. Use the data

### OTP

The transformed data can be used to build an OTP Graph. To do so it's recommended to use the per-agency zip files generated by the previous command.

#### 1. Build streetGraph
`java -Xmx12G -jar otp-2.2.0-shaded.jar --buildStreet .`

This command creates the `streetGraph.obj` file which contains the street data from OSM (e.g. http://download.geofabrik.de/europe/italy/nord-est-latest.osm.pbf). This process can be skipped in subsequent builds if the OSM data has not been updated.

#### 2. Build graph
`java -Xmx12G -jar otp-2.2.0-shaded.jar --loadStreet --save .`

This command loads the `streetGraph.obj` file created by the previous command and creates the `graph.obj` file which combines OSM data with the GTFS feeds.

#### 3. Launch the OTP server
`java -Xmx12G -jar otp-2.2.0-shaded.jar --load .`

This command launches the OTP server, loading the `graph.obj` file created by the previous command.

## 4. GTFSRT
`python real-time.py`

This command launches a process that parse the real time data for each agency. This command uses the data previously parsed by the `parse-dataset.py` command.
